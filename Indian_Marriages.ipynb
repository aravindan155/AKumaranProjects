{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from C:\\Users\\Aru\\Downloads\\archive\\marriage_data_india.csv\n",
      "Number of records: 10000\n",
      "\n",
      "Columns in the dataset:\n",
      "['ID', 'Marriage_Type', 'Age_at_Marriage', 'Gender', 'Education_Level', 'Caste_Match', 'Religion', 'Parental_Approval', 'Urban_Rural', 'Dowry_Exchanged', 'Marital_Satisfaction', 'Divorce_Status', 'Children_Count', 'Income_Level', 'Years_Since_Marriage', 'Spouse_Working', 'Inter-Caste', 'Inter-Religion']\n",
      "\n",
      "First few rows:\n",
      "   ID Marriage_Type  Age_at_Marriage  Gender Education_Level Caste_Match  \\\n",
      "0   1          Love               23    Male        Graduate   Different   \n",
      "1   2          Love               28  Female          School        Same   \n",
      "2   3      Arranged               39    Male    Postgraduate        Same   \n",
      "3   4      Arranged               26  Female          School   Different   \n",
      "4   5          Love               32  Female        Graduate        Same   \n",
      "\n",
      "  Religion Parental_Approval Urban_Rural Dowry_Exchanged Marital_Satisfaction  \\\n",
      "0    Hindu                No       Urban              No               Medium   \n",
      "1    Hindu               Yes       Rural             Yes                  Low   \n",
      "2   Muslim               Yes       Rural              No               Medium   \n",
      "3    Hindu               Yes       Urban             Yes                  Low   \n",
      "4    Hindu           Partial       Rural             Yes               Medium   \n",
      "\n",
      "  Divorce_Status  Children_Count Income_Level  Years_Since_Marriage  \\\n",
      "0            Yes               5       Middle                    34   \n",
      "1             No               3       Middle                    42   \n",
      "2             No               0         High                    25   \n",
      "3             No               0         High                    12   \n",
      "4             No               1       Middle                    41   \n",
      "\n",
      "  Spouse_Working Inter-Caste Inter-Religion  \n",
      "0             No          No             No  \n",
      "1             No          No            Yes  \n",
      "2             No          No             No  \n",
      "3             No         Yes             No  \n",
      "4             No          No            Yes  \n",
      "\n",
      "\n",
      "Chi-Square Test Analysis for Marriage Type Associations\n",
      "============================================================\n",
      "\n",
      "This analysis examines the association between Marriage Type (Love/Arranged)\n",
      "and several categorical variables using chi-square tests of independence.\n",
      "\n",
      "For each variable, we will:\n",
      "1. Create a contingency table\n",
      "2. Check chi-square test assumptions\n",
      "3. Perform appropriate statistical test (chi-square or Fisher's exact test)\n",
      "4. Report and interpret results\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing association between Marriage_Type and Caste_Match\n",
      "\n",
      "Contingency Table for Marriage_Type vs Caste_Match:\n",
      "Caste_Match    Different  Same\n",
      "Marriage_Type                 \n",
      "Arranged            1749  4273\n",
      "Love                1180  2798\n",
      "\n",
      "Expected Frequencies:\n",
      "Caste_Match    Different       Same\n",
      "Marriage_Type                      \n",
      "Arranged       1763.8438  4258.1562\n",
      "Love           1165.1562  2812.8438\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.4147\n",
      "p-value: 0.5196\n",
      "Statistically significant (α=0.05): False\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Caste_Match (p = 0.5196).\n",
      "\n",
      "============================================================\n",
      "Testing association between Marriage_Type and Urban_Rural\n",
      "\n",
      "Contingency Table for Marriage_Type vs Urban_Rural:\n",
      "Urban_Rural    Rural  Urban\n",
      "Marriage_Type              \n",
      "Arranged        2387   3635\n",
      "Love            1567   2411\n",
      "\n",
      "Expected Frequencies:\n",
      "Urban_Rural        Rural      Urban\n",
      "Marriage_Type                      \n",
      "Arranged       2381.0988  3640.9012\n",
      "Love           1572.9012  2405.0988\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.0509\n",
      "p-value: 0.8214\n",
      "Statistically significant (α=0.05): False\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Urban_Rural (p = 0.8214).\n",
      "\n",
      "============================================================\n",
      "Testing association between Marriage_Type and Divorce_Status\n",
      "\n",
      "Contingency Table for Marriage_Type vs Divorce_Status:\n",
      "Divorce_Status    No  Yes\n",
      "Marriage_Type            \n",
      "Arranged        5423  599\n",
      "Love            3576  402\n",
      "\n",
      "Expected Frequencies:\n",
      "Divorce_Status         No       Yes\n",
      "Marriage_Type                      \n",
      "Arranged        5419.1978  602.8022\n",
      "Love            3579.8022  398.1978\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.0505\n",
      "p-value: 0.8221\n",
      "Statistically significant (α=0.05): False\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Divorce_Status (p = 0.8221).\n",
      "\n",
      "============================================================\n",
      "Testing association between Marriage_Type and Spouse_Working\n",
      "\n",
      "Contingency Table for Marriage_Type vs Spouse_Working:\n",
      "Spouse_Working    No   Yes\n",
      "Marriage_Type             \n",
      "Arranged        3034  2988\n",
      "Love            1919  2059\n",
      "\n",
      "Expected Frequencies:\n",
      "Spouse_Working         No        Yes\n",
      "Marriage_Type                       \n",
      "Arranged        2982.6966  3039.3034\n",
      "Love            1970.3034  2007.6966\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 4.3100\n",
      "p-value: 0.0379\n",
      "Statistically significant (α=0.05): True\n",
      "\n",
      "Interpretation: There is a statistically significant association between\n",
      "Marriage_Type and Spouse_Working (p = 0.0379).\n",
      "Effect size (Cramer's V): 0.0208\n",
      "This represents a negligible effect size.\n",
      "\n",
      "============================================================\n",
      "Testing association between Marriage_Type and Inter-Caste\n",
      "\n",
      "Contingency Table for Marriage_Type vs Inter-Caste:\n",
      "Inter-Caste      No   Yes\n",
      "Marriage_Type            \n",
      "Arranged       4251  1771\n",
      "Love           2781  1197\n",
      "\n",
      "Expected Frequencies:\n",
      "Inter-Caste           No        Yes\n",
      "Marriage_Type                      \n",
      "Arranged       4234.6704  1787.3296\n",
      "Love           2797.3296  1180.6704\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.5012\n",
      "p-value: 0.4790\n",
      "Statistically significant (α=0.05): False\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Inter-Caste (p = 0.4790).\n",
      "\n",
      "============================================================\n",
      "Testing association between Marriage_Type and Inter-Religion\n",
      "\n",
      "Contingency Table for Marriage_Type vs Inter-Religion:\n",
      "Inter-Religion    No   Yes\n",
      "Marriage_Type             \n",
      "Arranged        4794  1228\n",
      "Love            3178   800\n",
      "\n",
      "Expected Frequencies:\n",
      "Inter-Religion         No        Yes\n",
      "Marriage_Type                       \n",
      "Arranged        4800.7384  1221.2616\n",
      "Love            3171.2616   806.7384\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.1005\n",
      "p-value: 0.7512\n",
      "Statistically significant (α=0.05): False\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Inter-Religion (p = 0.7512).\n",
      "\n",
      "============================================================\n",
      "\n",
      "Summary of Results:\n",
      "      Variable       Test Type Test Statistic p-value Significant Assumptions Met Effect Size\n",
      "   Caste_Match Chi-square test         0.4147  0.5196          No             Yes      0.0064\n",
      "   Urban_Rural Chi-square test         0.0509  0.8214          No             Yes      0.0023\n",
      "Divorce_Status Chi-square test         0.0505  0.8221          No             Yes      0.0022\n",
      "Spouse_Working Chi-square test         4.3100  0.0379         Yes             Yes      0.0208\n",
      "   Inter-Caste Chi-square test         0.5012  0.4790          No             Yes      0.0071\n",
      "Inter-Religion Chi-square test         0.1005  0.7512          No             Yes      0.0032\n",
      "\n",
      "Analysis complete. A visualization of the contingency tables has been saved as 'marriage_type_associations.png'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set file path for the data\n",
    "file_path = r\"C:\\Users\\Aru\\Downloads\\archive\\marriage_data_india.csv\"\n",
    "\n",
    "# Check if file exists and load data\n",
    "try:\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from {file_path}\")\n",
    "        print(f\"Number of records: {len(df)}\")\n",
    "        print(\"\\nColumns in the dataset:\")\n",
    "        print(df.columns.tolist())\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"File not found at: {file_path}\")\n",
    "        print(\"Creating sample data for demonstration instead.\")\n",
    "        \n",
    "        # Create sample data for demonstration\n",
    "        np.random.seed(42)\n",
    "        n = 500\n",
    "        \n",
    "        # Create sample data that mimics expected structure\n",
    "        data = {\n",
    "            'Marriage_Type': np.random.choice(['Love', 'Arranged'], size=n, p=[0.4, 0.6]),\n",
    "            'Caste_Match': np.random.choice(['Yes', 'No'], size=n, p=[0.7, 0.3]),\n",
    "            'Urban_Rural': np.random.choice(['Urban', 'Rural'], size=n, p=[0.6, 0.4]),\n",
    "            'Divorce_Status': np.random.choice(['Yes', 'No'], size=n, p=[0.2, 0.8]),\n",
    "            'Spouse_Working': np.random.choice(['Yes', 'No'], size=n, p=[0.5, 0.5]),\n",
    "            'Inter-Caste': np.random.choice(['Yes', 'No'], size=n, p=[0.25, 0.75]),\n",
    "            'Inter-Religion': np.random.choice(['Yes', 'No'], size=n, p=[0.15, 0.85])\n",
    "        }\n",
    "        \n",
    "        # Create the DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        print(\"\\nNote: This is sample data. Please verify the file path and try again.\")\n",
    "        print(\"Possible issues:\")\n",
    "        print(\"1. The file path may be incorrect.\")\n",
    "        print(\"2. The file may be named differently.\")\n",
    "        print(\"3. The file may be in a different location.\")\n",
    "        print(\"\\nSuggested actions:\")\n",
    "        print(\"1. Check that the file exists at the specified path.\")\n",
    "        print(\"2. Make sure the file name is exactly 'marriage_data_india.csv'.\")\n",
    "        print(\"3. Try using the full absolute path to the file.\")\n",
    "        print(\"4. If using Jupyter notebook, place the file in the same directory as the notebook.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading the data: {e}\")\n",
    "    \n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n = 500\n",
    "    \n",
    "    # Create sample data\n",
    "    data = {\n",
    "        'Marriage_Type': np.random.choice(['Love', 'Arranged'], size=n, p=[0.4, 0.6]),\n",
    "        'Caste_Match': np.random.choice(['Yes', 'No'], size=n, p=[0.7, 0.3]),\n",
    "        'Urban_Rural': np.random.choice(['Urban', 'Rural'], size=n, p=[0.6, 0.4]),\n",
    "        'Divorce_Status': np.random.choice(['Yes', 'No'], size=n, p=[0.2, 0.8]),\n",
    "        'Spouse_Working': np.random.choice(['Yes', 'No'], size=n, p=[0.5, 0.5]),\n",
    "        'Inter-Caste': np.random.choice(['Yes', 'No'], size=n, p=[0.25, 0.75]),\n",
    "        'Inter-Religion': np.random.choice(['Yes', 'No'], size=n, p=[0.15, 0.85])\n",
    "    }\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure column names are in the expected format\n",
    "# If needed, rename columns to match our expected format\n",
    "expected_columns = ['Marriage_Type', 'Caste_Match', 'Urban_Rural', 'Divorce_Status', \n",
    "                    'Spouse_Working', 'Inter-Caste', 'Inter-Religion']\n",
    "\n",
    "# Check if all expected columns exist (case insensitive)\n",
    "for expected_col in expected_columns:\n",
    "    if expected_col not in df.columns:\n",
    "        # Try to find a case-insensitive match\n",
    "        matches = [col for col in df.columns if col.lower() == expected_col.lower()]\n",
    "        if matches:\n",
    "            df.rename(columns={matches[0]: expected_col}, inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{expected_col}' not found in the dataset.\")\n",
    "\n",
    "# Introduction to the statistical approach\n",
    "print(\"\\n\\nChi-Square Test Analysis for Marriage Type Associations\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nThis analysis examines the association between Marriage Type (Love/Arranged)\")\n",
    "print(\"and several categorical variables using chi-square tests of independence.\")\n",
    "print(\"\\nFor each variable, we will:\")\n",
    "print(\"1. Create a contingency table\")\n",
    "print(\"2. Check chi-square test assumptions\")\n",
    "print(\"3. Perform appropriate statistical test (chi-square or Fisher's exact test)\")\n",
    "print(\"4. Report and interpret results\\n\")\n",
    "\n",
    "# Function to perform chi-square test or Fisher's exact test with assumption checking\n",
    "def perform_association_test(df, var, primary_var='Marriage_Type'):\n",
    "    \"\"\"\n",
    "    Perform chi-square test or Fisher's exact test based on assumptions.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The data\n",
    "    var (str): Variable to test for association with primary_var\n",
    "    primary_var (str): Primary variable (default 'Marriage_Type')\n",
    "    \n",
    "    Returns:\n",
    "    dict: Results of the test\n",
    "    \"\"\"\n",
    "    # Skip if the column doesn't exist\n",
    "    if var not in df.columns or primary_var not in df.columns:\n",
    "        print(f\"\\nSkipping test for {var} as it or {primary_var} is not in the dataset.\")\n",
    "        return None\n",
    "    \n",
    "    # Skip if the column has all missing values\n",
    "    if df[var].isna().all() or df[primary_var].isna().all():\n",
    "        print(f\"\\nSkipping test for {var} as it or {primary_var} contains all missing values.\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy with non-missing values for this test\n",
    "    test_df = df[[primary_var, var]].dropna()\n",
    "    \n",
    "    # Skip if too few data points after dropping missing values\n",
    "    if len(test_df) < 10:\n",
    "        print(f\"\\nSkipping test for {var} as there are too few non-missing values.\")\n",
    "        return None\n",
    "    \n",
    "    # Create contingency table\n",
    "    try:\n",
    "        cont_table = pd.crosstab(test_df[primary_var], test_df[var])\n",
    "        print(f\"\\nContingency Table for {primary_var} vs {var}:\")\n",
    "        print(cont_table)\n",
    "        \n",
    "        # Check if contingency table dimensions are valid (at least 2x2)\n",
    "        if cont_table.shape[0] < 2 or cont_table.shape[1] < 2:\n",
    "            print(f\"\\nSkipping test for {var} as the contingency table doesn't have at least two categories for each variable.\")\n",
    "            return None\n",
    "        \n",
    "        # Check assumptions for chi-square test\n",
    "        # 1. Independence assumption is assumed from research design\n",
    "        # 2. Check if all expected frequencies are at least 5\n",
    "        chi2, p, dof, expected = chi2_contingency(cont_table)\n",
    "        \n",
    "        # Print expected frequencies\n",
    "        print(f\"\\nExpected Frequencies:\")\n",
    "        expected_df = pd.DataFrame(\n",
    "            expected, \n",
    "            index=cont_table.index, \n",
    "            columns=cont_table.columns\n",
    "        )\n",
    "        print(expected_df)\n",
    "        \n",
    "        # Check if any expected frequency is less than 5\n",
    "        assumption_met = np.all(expected >= 5)\n",
    "        print(f\"\\nAll expected frequencies >= 5: {assumption_met}\")\n",
    "        \n",
    "        # Perform appropriate test\n",
    "        if assumption_met:\n",
    "            # Chi-square test\n",
    "            test_type = \"Chi-square test\"\n",
    "            stat, p_value, _, _ = chi2_contingency(cont_table)\n",
    "            test_stat = stat\n",
    "        else:\n",
    "            # Fisher's exact test for 2x2 tables\n",
    "            if cont_table.shape == (2, 2):\n",
    "                test_type = \"Fisher's exact test\"\n",
    "                odds_ratio, p_value = fisher_exact(cont_table)\n",
    "                test_stat = odds_ratio\n",
    "            else:\n",
    "                # For larger tables where assumptions aren't met, report chi-square with warning\n",
    "                test_type = \"Chi-square test (Warning: assumptions not met)\"\n",
    "                stat, p_value, _, _ = chi2_contingency(cont_table)\n",
    "                test_stat = stat\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            'variable': var,\n",
    "            'test_type': test_type,\n",
    "            'test_statistic': test_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < 0.05,\n",
    "            'assumption_met': assumption_met,\n",
    "            'contingency_table': cont_table,\n",
    "            'expected_frequencies': expected_df\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError performing test for {var}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Variables to test\n",
    "variables = ['Caste_Match', 'Urban_Rural', 'Divorce_Status', \n",
    "            'Spouse_Working', 'Inter-Caste', 'Inter-Religion']\n",
    "\n",
    "# Perform the tests and collect results\n",
    "results = []\n",
    "for var in variables:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Testing association between Marriage_Type and {var}\")\n",
    "    result = perform_association_test(df, var)\n",
    "    \n",
    "    if result is None:\n",
    "        print(f\"Could not perform test for {var}.\")\n",
    "        continue\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nResults of {result['test_type']}:\")\n",
    "    if result['test_type'] == \"Fisher's exact test\":\n",
    "        print(f\"Odds Ratio: {result['test_statistic']:.4f}\")\n",
    "    else:\n",
    "        print(f\"Chi-square statistic: {result['test_statistic']:.4f}\")\n",
    "    print(f\"p-value: {result['p_value']:.4f}\")\n",
    "    print(f\"Statistically significant (α=0.05): {result['significant']}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if result['significant']:\n",
    "        print(f\"\\nInterpretation: There is a statistically significant association between\")\n",
    "        print(f\"Marriage_Type and {var} (p = {result['p_value']:.4f}).\")\n",
    "        \n",
    "        # Add effect size calculation (Cramer's V) for chi-square\n",
    "        if \"Chi-square\" in result['test_type']:\n",
    "            n = result['contingency_table'].sum().sum()\n",
    "            min_dim = min(result['contingency_table'].shape) - 1\n",
    "            cramer_v = np.sqrt(result['test_statistic'] / (n * min_dim))\n",
    "            print(f\"Effect size (Cramer's V): {cramer_v:.4f}\")\n",
    "            \n",
    "            # Interpret effect size\n",
    "            if cramer_v < 0.1:\n",
    "                effect = \"negligible\"\n",
    "            elif cramer_v < 0.3:\n",
    "                effect = \"small\"\n",
    "            elif cramer_v < 0.5:\n",
    "                effect = \"medium\"\n",
    "            else:\n",
    "                effect = \"large\"\n",
    "            print(f\"This represents a {effect} effect size.\")\n",
    "    else:\n",
    "        print(f\"\\nInterpretation: There is no statistically significant association between\")\n",
    "        print(f\"Marriage_Type and {var} (p = {result['p_value']:.4f}).\")\n",
    "    \n",
    "    results.append(result)\n",
    "\n",
    "# Create a summary table if we have results\n",
    "if results:\n",
    "    summary_data = []\n",
    "    for result in results:\n",
    "        # Add effect size calculation for summary table\n",
    "        if \"Chi-square\" in result['test_type']:\n",
    "            n = result['contingency_table'].sum().sum()\n",
    "            min_dim = min(result['contingency_table'].shape) - 1\n",
    "            cramer_v = np.sqrt(result['test_statistic'] / (n * min_dim))\n",
    "            effect_size = f\"{cramer_v:.4f}\"\n",
    "        else:\n",
    "            effect_size = \"N/A\"  # For Fisher's exact test\n",
    "            \n",
    "        summary_data.append({\n",
    "            'Variable': result['variable'],\n",
    "            'Test Type': result['test_type'],\n",
    "            'Test Statistic': f\"{result['test_statistic']:.4f}\",\n",
    "            'p-value': f\"{result['p_value']:.4f}\",\n",
    "            'Significant': 'Yes' if result['significant'] else 'No',\n",
    "            'Assumptions Met': 'Yes' if result['assumption_met'] else 'No',\n",
    "            'Effect Size': effect_size\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # Visualization of results\n",
    "    if len(results) > 0:\n",
    "        num_rows = (len(results) + 1) // 2  # Calculate rows needed\n",
    "        plt.figure(figsize=(12, 3 * num_rows))\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            plt.subplot(num_rows, 2, i+1)\n",
    "            \n",
    "            # Create a heatmap of the contingency table\n",
    "            sns.heatmap(\n",
    "                result['contingency_table'], \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='YlGnBu',\n",
    "                cbar=False\n",
    "            )\n",
    "            \n",
    "            # Add a more informative title with p-value and significance\n",
    "            sig_marker = \"*\" if result['significant'] else \"ns\"\n",
    "            plt.title(f\"Marriage_Type vs {result['variable']}\\np = {result['p_value']:.4f} {sig_marker}\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "        try:\n",
    "            plt.savefig('marriage_type_associations.png')\n",
    "            print(\"\\nAnalysis complete. A visualization of the contingency tables has been saved as 'marriage_type_associations.png'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nCould not save visualization: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "else:\n",
    "    print(\"\\nNo valid results to summarize. Please check your data and file path.\")\n",
    "    print(\"If using your own data, ensure the column names match the expected format:\")\n",
    "    print(\", \".join(expected_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above binary variables were tested with Marriage_Type. Assumptions were tested first in order to determine if a non-parametric test was needed to be performed. \n",
    "According to these results, the only variable that was associated with Marriage_Type (arranged v love) was Spouse_Working (whether one's spouse was working or not); however, this effect size was small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from C:\\Users\\Aru\\Downloads\\archive\\marriage_data_india.csv\n",
      "Number of records: 10000\n",
      "\n",
      "Columns in the dataset:\n",
      "['ID', 'Marriage_Type', 'Age_at_Marriage', 'Gender', 'Education_Level', 'Caste_Match', 'Religion', 'Parental_Approval', 'Urban_Rural', 'Dowry_Exchanged', 'Marital_Satisfaction', 'Divorce_Status', 'Children_Count', 'Income_Level', 'Years_Since_Marriage', 'Spouse_Working', 'Inter-Caste', 'Inter-Religion']\n",
      "\n",
      "First few rows:\n",
      "   ID Marriage_Type  Age_at_Marriage  Gender Education_Level Caste_Match  \\\n",
      "0   1          Love               23    Male        Graduate   Different   \n",
      "1   2          Love               28  Female          School        Same   \n",
      "2   3      Arranged               39    Male    Postgraduate        Same   \n",
      "3   4      Arranged               26  Female          School   Different   \n",
      "4   5          Love               32  Female        Graduate        Same   \n",
      "\n",
      "  Religion Parental_Approval Urban_Rural Dowry_Exchanged Marital_Satisfaction  \\\n",
      "0    Hindu                No       Urban              No               Medium   \n",
      "1    Hindu               Yes       Rural             Yes                  Low   \n",
      "2   Muslim               Yes       Rural              No               Medium   \n",
      "3    Hindu               Yes       Urban             Yes                  Low   \n",
      "4    Hindu           Partial       Rural             Yes               Medium   \n",
      "\n",
      "  Divorce_Status  Children_Count Income_Level  Years_Since_Marriage  \\\n",
      "0            Yes               5       Middle                    34   \n",
      "1             No               3       Middle                    42   \n",
      "2             No               0         High                    25   \n",
      "3             No               0         High                    12   \n",
      "4             No               1       Middle                    41   \n",
      "\n",
      "  Spouse_Working Inter-Caste Inter-Religion  \n",
      "0             No          No             No  \n",
      "1             No          No            Yes  \n",
      "2             No          No             No  \n",
      "3             No         Yes             No  \n",
      "4             No          No            Yes  \n",
      "\n",
      "Unique values in Marriage_Type: ['Love' 'Arranged']\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CHI-SQUARE ANALYSIS: Marriage_Type vs Specified Variables\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Education_Level\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Education_Level:\n",
      "Education_Level  Graduate  PhD  Postgraduate  School\n",
      "Marriage_Type                                       \n",
      "Arranged             2342  592          1203    1885\n",
      "Love                 1601  374           815    1188\n",
      "\n",
      "Expected Frequencies:\n",
      "Education_Level   Graduate       PhD  Postgraduate     School\n",
      "Marriage_Type                                                \n",
      "Arranged         2374.4746  581.7252     1215.2396  1850.5606\n",
      "Love             1568.5254  384.2748      802.7604  1222.4394\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 3.4938\n",
      "p-value: 0.3216\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0187\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Education_Level (p = 0.3216).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Caste_Match\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Caste_Match:\n",
      "Caste_Match    Different  Same\n",
      "Marriage_Type                 \n",
      "Arranged            1749  4273\n",
      "Love                1180  2798\n",
      "\n",
      "Expected Frequencies:\n",
      "Caste_Match    Different       Same\n",
      "Marriage_Type                      \n",
      "Arranged       1763.8438  4258.1562\n",
      "Love           1165.1562  2812.8438\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.4147\n",
      "p-value: 0.5196\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0064\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Caste_Match (p = 0.5196).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Religion\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Religion:\n",
      "Religion       Christian  Hindu  Muslim  Others  Sikh\n",
      "Marriage_Type                                        \n",
      "Arranged             621   3640    1156     308   297\n",
      "Love                 369   2394     783     223   209\n",
      "\n",
      "Expected Frequencies:\n",
      "Religion       Christian      Hindu     Muslim    Others      Sikh\n",
      "Marriage_Type                                                     \n",
      "Arranged         596.178  3633.6748  1167.6658  319.7682  304.7132\n",
      "Love             393.822  2400.3252   771.3342  211.2318  201.2868\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 4.4982\n",
      "p-value: 0.3428\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0212\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Religion (p = 0.3428).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Parental_Approval\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Parental_Approval:\n",
      "Parental_Approval   No  Partial   Yes\n",
      "Marriage_Type                        \n",
      "Arranged           587     1190  4245\n",
      "Love               446      763  2769\n",
      "\n",
      "Expected Frequencies:\n",
      "Parental_Approval        No    Partial        Yes\n",
      "Marriage_Type                                    \n",
      "Arranged           622.0726  1176.0966  4223.8308\n",
      "Love               410.9274   776.9034  2790.1692\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 5.6507\n",
      "p-value: 0.0593\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0238\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Parental_Approval (p = 0.0593).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Dowry_Exchanged\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Dowry_Exchanged:\n",
      "Dowry_Exchanged    No  Not Disclosed   Yes\n",
      "Marriage_Type                             \n",
      "Arranged         3635            601  1786\n",
      "Love             2367            401  1210\n",
      "\n",
      "Expected Frequencies:\n",
      "Dowry_Exchanged         No  Not Disclosed        Yes\n",
      "Marriage_Type                                       \n",
      "Arranged         3614.4044       603.4044  1804.1912\n",
      "Love             2387.5956       398.5956  1191.8088\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.7802\n",
      "p-value: 0.6770\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0088\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Dowry_Exchanged (p = 0.6770).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Marital_Satisfaction\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Marital_Satisfaction:\n",
      "Marital_Satisfaction  High   Low  Medium\n",
      "Marriage_Type                           \n",
      "Arranged              1811  1197    3014\n",
      "Love                  1182   809    1987\n",
      "\n",
      "Expected Frequencies:\n",
      "Marital_Satisfaction       High        Low     Medium\n",
      "Marriage_Type                                        \n",
      "Arranged              1802.3846  1208.0132  3011.6022\n",
      "Love                  1190.6154   797.9868  1989.3978\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 0.3607\n",
      "p-value: 0.8350\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0060\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Marital_Satisfaction (p = 0.8350).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Children_Count\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Children_Count:\n",
      "Children_Count    0    1     2     3     4     5\n",
      "Marriage_Type                                   \n",
      "Arranged        947  995  1019  1032  1025  1004\n",
      "Love            643  736   635   666   655   643\n",
      "\n",
      "Expected Frequencies:\n",
      "Children_Count        0          1         2          3         4         5\n",
      "Marriage_Type                                                              \n",
      "Arranged        957.498  1042.4082  996.0388  1022.5356  1011.696  991.8234\n",
      "Love            632.502   688.5918  657.9612   675.4644   668.304  655.1766\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 8.0758\n",
      "p-value: 0.1521\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0284\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Children_Count (p = 0.1521).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Testing association between Marriage_Type and Income_Level\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Contingency Table for Marriage_Type vs Income_Level:\n",
      "Income_Level   High   Low  Middle\n",
      "Marriage_Type                    \n",
      "Arranged       1234  1813    2975\n",
      "Love            789  1181    2008\n",
      "\n",
      "Expected Frequencies:\n",
      "Income_Level        High        Low     Middle\n",
      "Marriage_Type                                 \n",
      "Arranged       1218.2506  1802.9868  3000.7626\n",
      "Love            804.7494  1191.0132  1982.2374\n",
      "\n",
      "All expected frequencies >= 5: True\n",
      "\n",
      "Results of Chi-square test:\n",
      "Chi-square statistic: 1.2076\n",
      "p-value: 0.5467\n",
      "Statistically significant (α=0.05): False\n",
      "Effect size (Cramer's V): 0.0110\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Interpretation: There is no statistically significant association between\n",
      "Marriage_Type and Income_Level (p = 0.5467).\n",
      "\n",
      "======================================================================\n",
      "\n",
      "SUMMARY OF CHI-SQUARE TESTS (sorted by p-value)\n",
      "======================================================================\n",
      "            Variable       Test Type Test Statistic p-value Significant Effect Size\n",
      "   Parental_Approval Chi-square test         5.6507  0.0593          No      0.0238\n",
      "      Children_Count Chi-square test         8.0758  0.1521          No      0.0284\n",
      "     Education_Level Chi-square test         3.4938  0.3216          No      0.0187\n",
      "            Religion Chi-square test         4.4982  0.3428          No      0.0212\n",
      "         Caste_Match Chi-square test         0.4147  0.5196          No      0.0064\n",
      "        Income_Level Chi-square test         1.2076  0.5467          No      0.0110\n",
      "     Dowry_Exchanged Chi-square test         0.7802  0.6770          No      0.0088\n",
      "Marital_Satisfaction Chi-square test         0.3607  0.8350          No      0.0060\n",
      "\n",
      "Visualization saved as 'marriage_type_associations.png'.\n",
      "\n",
      "NOTES ON INTERPRETATION:\n",
      "- A significant p-value (< 0.05) indicates an association between Marriage_Type and the variable.\n",
      "- Cramer's V measures the strength of association (0 to 1):\n",
      "  * < 0.1: Negligible association\n",
      "  * 0.1 to < 0.3: Small association\n",
      "  * 0.3 to < 0.5: Moderate association\n",
      "  * ≥ 0.5: Strong association\n",
      "- The heat maps show the percentage distribution of responses by marriage type.\n",
      "\n",
      "No statistically significant associations were found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set file path for the data\n",
    "file_path = r\"C:\\Users\\Aru\\Downloads\\archive\\marriage_data_india.csv\"\n",
    "\n",
    "# Function to check if column exists in dataset\n",
    "def check_column(df, column_name):\n",
    "    if column_name not in df.columns:\n",
    "        # Try to find a case-insensitive match\n",
    "        matches = [col for col in df.columns if col.lower() == column_name.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "        else:\n",
    "            return None\n",
    "    return column_name\n",
    "\n",
    "# Function to perform chi-square test or Fisher's exact test\n",
    "def perform_chi_square_test(df, var1, var2):\n",
    "    \"\"\"\n",
    "    Perform chi-square test or Fisher's exact test based on assumptions.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The data\n",
    "    var1 (str): First variable name\n",
    "    var2 (str): Second variable name\n",
    "    \n",
    "    Returns:\n",
    "    dict: Results of the test\n",
    "    \"\"\"\n",
    "    # Get correct column names\n",
    "    var1_col = check_column(df, var1)\n",
    "    var2_col = check_column(df, var2)\n",
    "    \n",
    "    # Skip if any column doesn't exist\n",
    "    if not var1_col or not var2_col:\n",
    "        print(f\"\\nSkipping test: Could not find columns {var1} or {var2}\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy with only non-missing values for this test\n",
    "    test_df = df[[var1_col, var2_col]].dropna()\n",
    "    \n",
    "    # Skip if too few data points after dropping missing values\n",
    "    if len(test_df) < 10:\n",
    "        print(f\"\\nSkipping test: Too few non-missing values for {var1_col} vs {var2_col}\")\n",
    "        return None\n",
    "        \n",
    "    # For continuous variables, bin them first\n",
    "    if pd.api.types.is_numeric_dtype(test_df[var2_col]):\n",
    "        if test_df[var2_col].nunique() > 10:  # Arbitrary cutoff for binning\n",
    "            try:\n",
    "                # Try to bin the variable into quartiles\n",
    "                test_df[f\"{var2_col}_binned\"] = pd.qcut(test_df[var2_col], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "                var2_col = f\"{var2_col}_binned\"\n",
    "                print(f\"Binned continuous variable {var2} into quartiles.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not bin variable {var2}: {e}\")\n",
    "                # If binning fails, let's try equal-width bins\n",
    "                try:\n",
    "                    test_df[f\"{var2_col}_binned\"] = pd.cut(test_df[var2_col], bins=4, labels=['Bin1', 'Bin2', 'Bin3', 'Bin4'])\n",
    "                    var2_col = f\"{var2_col}_binned\"\n",
    "                    print(f\"Binned continuous variable {var2} into equal-width bins.\")\n",
    "                except:\n",
    "                    print(f\"Could not bin variable {var2} with equal-width bins either. Using original values.\")\n",
    "    \n",
    "    # Create contingency table\n",
    "    try:\n",
    "        cont_table = pd.crosstab(test_df[var1_col], test_df[var2_col])\n",
    "        print(f\"\\nContingency Table for {var1_col} vs {var2_col}:\")\n",
    "        print(cont_table)\n",
    "        \n",
    "        # Check if contingency table dimensions are valid (at least 2x2)\n",
    "        if cont_table.shape[0] < 2 or cont_table.shape[1] < 2:\n",
    "            print(f\"\\nSkipping test: The contingency table doesn't have at least two categories for each variable.\")\n",
    "            return None\n",
    "        \n",
    "        # Check assumptions for chi-square test\n",
    "        chi2, p, dof, expected = chi2_contingency(cont_table)\n",
    "        \n",
    "        # Print expected frequencies\n",
    "        print(f\"\\nExpected Frequencies:\")\n",
    "        expected_df = pd.DataFrame(\n",
    "            expected, \n",
    "            index=cont_table.index, \n",
    "            columns=cont_table.columns\n",
    "        )\n",
    "        print(expected_df)\n",
    "        \n",
    "        # Check if any expected frequency is less than 5\n",
    "        assumption_met = np.all(expected >= 5)\n",
    "        print(f\"\\nAll expected frequencies >= 5: {assumption_met}\")\n",
    "        \n",
    "        # Perform appropriate test\n",
    "        if assumption_met:\n",
    "            # Chi-square test\n",
    "            test_type = \"Chi-square test\"\n",
    "            stat, p_value, _, _ = chi2_contingency(cont_table)\n",
    "            test_stat = stat\n",
    "        else:\n",
    "            # Fisher's exact test for 2x2 tables\n",
    "            if cont_table.shape == (2, 2):\n",
    "                test_type = \"Fisher's exact test\"\n",
    "                odds_ratio, p_value = fisher_exact(cont_table)\n",
    "                test_stat = odds_ratio\n",
    "            else:\n",
    "                # For larger tables where assumptions aren't met, report chi-square with warning\n",
    "                test_type = \"Chi-square test (Warning: assumptions not met)\"\n",
    "                stat, p_value, _, _ = chi2_contingency(cont_table)\n",
    "                test_stat = stat\n",
    "        \n",
    "        # Calculate Cramer's V for effect size (for chi-square)\n",
    "        if \"Chi-square\" in test_type:\n",
    "            n = cont_table.sum().sum()\n",
    "            min_dim = min(cont_table.shape) - 1\n",
    "            cramers_v = np.sqrt(stat / (n * min_dim))\n",
    "        else:\n",
    "            cramers_v = None\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            'variable': var2_col,\n",
    "            'test_type': test_type,\n",
    "            'test_statistic': test_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < 0.05,\n",
    "            'assumption_met': assumption_met,\n",
    "            'contingency_table': cont_table,\n",
    "            'expected_frequencies': expected_df,\n",
    "            'cramers_v': cramers_v\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError performing test for {var1_col} vs {var2_col}: {e}\")\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    # Check if file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from {file_path}\")\n",
    "        print(f\"Number of records: {len(df)}\")\n",
    "        print(\"\\nColumns in the dataset:\")\n",
    "        print(df.columns.tolist())\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"File not found at: {file_path}\")\n",
    "        print(\"Creating sample data for demonstration instead.\")\n",
    "        \n",
    "        # Create sample data for demonstration\n",
    "        np.random.seed(42)\n",
    "        n = 500\n",
    "        \n",
    "        # Create sample data\n",
    "        education_levels = ['Primary', 'Secondary', 'Graduate', 'Post-Graduate']\n",
    "        religion = ['Hindu', 'Muslim', 'Christian', 'Sikh', 'Other']\n",
    "        income_levels = ['Low', 'Medium', 'High', 'Very High']\n",
    "        \n",
    "        marriage_type = np.random.choice(['Love', 'Arranged'], size=n, p=[0.4, 0.6])\n",
    "        \n",
    "        # Education_Level - slightly higher education in love marriages\n",
    "        p_edu_high = np.where(marriage_type == 'Love', [0.1, 0.3, 0.4, 0.2], [0.2, 0.4, 0.3, 0.1])\n",
    "        education_level = [np.random.choice(education_levels, p=p) for p in p_edu_high]\n",
    "        \n",
    "        # Caste_Match - more likely in arranged marriages\n",
    "        p_caste_match = np.where(marriage_type == 'Arranged', 0.85, 0.45)\n",
    "        caste_match = np.random.binomial(1, p_caste_match, n) == 1\n",
    "        caste_match = np.where(caste_match, 'Yes', 'No')\n",
    "        \n",
    "        # Religion - no strong pattern\n",
    "        religion_choice = np.random.choice(religion, size=n)\n",
    "        \n",
    "        # Parental_Approval - higher in arranged marriages\n",
    "        p_approval = np.where(marriage_type == 'Arranged', 0.9, 0.6)\n",
    "        parental_approval = np.random.binomial(1, p_approval, n) == 1\n",
    "        parental_approval = np.where(parental_approval, 'Yes', 'No')\n",
    "        \n",
    "        # Dowry_Exchanged - more common in arranged marriages\n",
    "        p_dowry = np.where(marriage_type == 'Arranged', 0.7, 0.3)\n",
    "        dowry_exchanged = np.random.binomial(1, p_dowry, n) == 1\n",
    "        dowry_exchanged = np.where(dowry_exchanged, 'Yes', 'No')\n",
    "        \n",
    "        # Marital_Satisfaction - slightly higher in love marriages\n",
    "        marital_satisfaction = np.random.choice(['Low', 'Medium', 'High'], size=n, \n",
    "                                             p=np.where(marriage_type == 'Love', \n",
    "                                                        [0.2, 0.3, 0.5], \n",
    "                                                        [0.3, 0.4, 0.3]))\n",
    "        \n",
    "        # Children_Count - no strong pattern\n",
    "        children_count = np.random.poisson(2, n)\n",
    "        \n",
    "        # Income_Level - no strong pattern\n",
    "        income_level = np.random.choice(income_levels, size=n)\n",
    "        \n",
    "        # Create the DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Marriage_Type': marriage_type,\n",
    "            'Education_Level': education_level,\n",
    "            'Caste_Match': caste_match,\n",
    "            'Religion': religion_choice,\n",
    "            'Parental_Approval': parental_approval,\n",
    "            'Dowry_Exchanged': dowry_exchanged,\n",
    "            'Marital_Satisfaction': marital_satisfaction,\n",
    "            'Children_Count': children_count,\n",
    "            'Income_Level': income_level\n",
    "        })\n",
    "        \n",
    "        print(\"\\nNote: This is sample data. Please verify the file path and try again.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading the data: {e}\")\n",
    "    # Similar sample data creation as above would go here if this exception is triggered\n",
    "\n",
    "# Get the correct column name for Marriage_Type\n",
    "marriage_type_col = check_column(df, 'Marriage_Type')\n",
    "if not marriage_type_col:\n",
    "    print(\"Error: Marriage_Type column not found in the dataset.\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    exit()\n",
    "\n",
    "# Print unique values of Marriage_Type to verify\n",
    "print(f\"\\nUnique values in {marriage_type_col}: {df[marriage_type_col].unique()}\")\n",
    "\n",
    "# List of variables to test against Marriage_Type\n",
    "variables_to_test = [\n",
    "    'Education_Level', \n",
    "    'Caste_Match', \n",
    "    'Religion', \n",
    "    'Parental_Approval', \n",
    "    'Dowry_Exchanged', \n",
    "    'Marital_Satisfaction', \n",
    "    'Children_Count', \n",
    "    'Income_Level'\n",
    "]\n",
    "\n",
    "# Perform chi-square tests for Marriage_Type vs each specified variable\n",
    "results = []\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"CHI-SQUARE ANALYSIS: Marriage_Type vs Specified Variables\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for var in variables_to_test:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(f\"Testing association between {marriage_type_col} and {var}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    result = perform_chi_square_test(df, marriage_type_col, var)\n",
    "    \n",
    "    if result:\n",
    "        # Print results\n",
    "        print(f\"\\nResults of {result['test_type']}:\")\n",
    "        if result['test_type'] == \"Fisher's exact test\":\n",
    "            print(f\"Odds Ratio: {result['test_statistic']:.4f}\")\n",
    "        else:\n",
    "            print(f\"Chi-square statistic: {result['test_statistic']:.4f}\")\n",
    "        print(f\"p-value: {result['p_value']:.4f}\")\n",
    "        print(f\"Statistically significant (α=0.05): {result['significant']}\")\n",
    "        \n",
    "        # Print effect size for chi-square tests\n",
    "        if result['cramers_v'] is not None:\n",
    "            print(f\"Effect size (Cramer's V): {result['cramers_v']:.4f}\")\n",
    "            \n",
    "            # Interpret effect size\n",
    "            if result['cramers_v'] < 0.1:\n",
    "                effect = \"negligible\"\n",
    "            elif result['cramers_v'] < 0.3:\n",
    "                effect = \"small\"\n",
    "            elif result['cramers_v'] < 0.5:\n",
    "                effect = \"moderate\"\n",
    "            else:\n",
    "                effect = \"large\"\n",
    "            print(f\"This represents a {effect} effect size.\")\n",
    "        \n",
    "        # Interpretation\n",
    "        if result['significant']:\n",
    "            print(f\"\\nInterpretation: There is a statistically significant association between\")\n",
    "            print(f\"{marriage_type_col} and {result['variable']} (p = {result['p_value']:.4f}).\")\n",
    "            \n",
    "            # Analyze the patterns in contingency table\n",
    "            table = result['contingency_table']\n",
    "            \n",
    "            # For each type of marriage, see which category has higher percentage\n",
    "            try:\n",
    "                row_percentages = table.div(table.sum(axis=1), axis=0) * 100\n",
    "                print(\"\\nPercentage breakdown by marriage type:\")\n",
    "                print(row_percentages)\n",
    "                \n",
    "                # Describe the key finding\n",
    "                marriage_types = table.index.tolist()\n",
    "                \n",
    "                for m_type in marriage_types:\n",
    "                    max_cat = row_percentages.loc[m_type].idxmax()\n",
    "                    max_pct = row_percentages.loc[m_type, max_cat]\n",
    "                    print(f\"- {m_type} marriages have higher percentage of '{max_cat}' ({max_pct:.1f}%)\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not calculate percentages: {e}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"\\nInterpretation: There is no statistically significant association between\")\n",
    "            print(f\"{marriage_type_col} and {result['variable']} (p = {result['p_value']:.4f}).\")\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "# Create a summary table\n",
    "if results:\n",
    "    summary_data = []\n",
    "    for result in results:\n",
    "        summary_data.append({\n",
    "            'Variable': result['variable'],\n",
    "            'Test Type': result['test_type'],\n",
    "            'Test Statistic': f\"{result['test_statistic']:.4f}\",\n",
    "            'p-value': f\"{result['p_value']:.4f}\",\n",
    "            'Significant': 'Yes' if result['significant'] else 'No',\n",
    "            'Effect Size': f\"{result['cramers_v']:.4f}\" if result['cramers_v'] is not None else 'N/A'\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    # Sort by p-value to highlight most significant associations first\n",
    "    summary_df = summary_df.sort_values('p-value')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nSUMMARY OF CHI-SQUARE TESTS (sorted by p-value)\")\n",
    "    print(\"=\"*70)\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # Create visualizations\n",
    "    if len(results) > 0:\n",
    "        # Create a grid of plots\n",
    "        num_rows = (len(results) + 1) // 2\n",
    "        fig, axes = plt.subplots(num_rows, 2, figsize=(15, 5 * num_rows))\n",
    "        axes = axes.flatten() if num_rows > 1 else [axes] if isinstance(axes, np.ndarray) else [axes]\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            if i < len(axes):  # Ensure we don't go out of bounds\n",
    "                ax = axes[i]\n",
    "                \n",
    "                # Create a heatmap of the contingency table\n",
    "                cont_table = result['contingency_table']\n",
    "                \n",
    "                try:\n",
    "                    # Calculate percentages by row\n",
    "                    normalized_table = cont_table.div(cont_table.sum(axis=1), axis=0) * 100\n",
    "                    \n",
    "                    # Plot the heatmap\n",
    "                    sns.heatmap(\n",
    "                        normalized_table,\n",
    "                        annot=True, \n",
    "                        fmt='.1f', \n",
    "                        cmap='YlGnBu',\n",
    "                        cbar_kws={'label': 'Percentage (%)'},\n",
    "                        ax=ax\n",
    "                    )\n",
    "                    \n",
    "                    # Add title with p-value and significance\n",
    "                    sig_marker = \"*\" if result['significant'] else \"ns\"\n",
    "                    effect_size = f\", V={result['cramers_v']:.2f}\" if result['cramers_v'] is not None else \"\"\n",
    "                    ax.set_title(f\"{marriage_type_col} vs {result['variable']}\\np = {result['p_value']:.4f} {sig_marker}{effect_size}\")\n",
    "                except Exception as e:\n",
    "                    ax.text(0.5, 0.5, f\"Could not create heatmap: {e}\", \n",
    "                            ha='center', va='center', transform=ax.transAxes)\n",
    "        \n",
    "        # Hide any unused subplots\n",
    "        for j in range(i+1, len(axes)):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        try:\n",
    "            plt.savefig('marriage_type_associations.png')\n",
    "            print(\"\\nVisualization saved as 'marriage_type_associations.png'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nCould not save visualization: {e}\")\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    # Print final notes\n",
    "    print(\"\\nNOTES ON INTERPRETATION:\")\n",
    "    print(\"- A significant p-value (< 0.05) indicates an association between Marriage_Type and the variable.\")\n",
    "    print(\"- Cramer's V measures the strength of association (0 to 1):\")\n",
    "    print(\"  * < 0.1: Negligible association\")\n",
    "    print(\"  * 0.1 to < 0.3: Small association\")\n",
    "    print(\"  * 0.3 to < 0.5: Moderate association\")\n",
    "    print(\"  * ≥ 0.5: Strong association\")\n",
    "    print(\"- The heat maps show the percentage distribution of responses by marriage type.\")\n",
    "    \n",
    "    # Print specific practical interpretations based on significant findings\n",
    "    significant_results = [r for r in results if r['significant']]\n",
    "    if significant_results:\n",
    "        print(\"\\nKEY FINDINGS:\")\n",
    "        for i, result in enumerate(significant_results):\n",
    "            var = result['variable']\n",
    "            print(f\"{i+1}. {var} is significantly associated with Marriage_Type (p={result['p_value']:.4f})\")\n",
    "            \n",
    "            if result['cramers_v'] is not None:\n",
    "                strength = \"weak\" if result['cramers_v'] < 0.3 else \"moderate\" if result['cramers_v'] < 0.5 else \"strong\"\n",
    "                print(f\"   • This is a {strength} association (Cramer's V = {result['cramers_v']:.2f})\")\n",
    "            \n",
    "            # Try to provide some specific insights about patterns\n",
    "            try:\n",
    "                table = result['contingency_table']\n",
    "                row_pcts = table.div(table.sum(axis=1), axis=0) * 100\n",
    "                \n",
    "                # For each marriage type, find the most common category\n",
    "                for m_type in table.index:\n",
    "                    max_cat = row_pcts.loc[m_type].idxmax()\n",
    "                    max_pct = row_pcts.loc[m_type, max_cat]\n",
    "                    print(f\"   • {m_type} marriages are more likely to have {var}={max_cat} ({max_pct:.1f}%)\")\n",
    "            except:\n",
    "                pass  # Skip detailed pattern analysis if it fails\n",
    "    else:\n",
    "        print(\"\\nNo statistically significant associations were found.\")\n",
    "else:\n",
    "    print(\"\\nNo valid results to summarize. Please check your data and file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous analysis, the chi-Square test was used to determine the relationship between Marriage Type and categorical variables stated above. None were deemed statistically significant, with Parental Approval being the closest to significant with a negligable effect size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from C:\\Users\\Aru\\Downloads\\archive\\marriage_data_india.csv\n",
      "Number of records: 10000\n",
      "\n",
      "Columns in the dataset:\n",
      "['ID', 'Marriage_Type', 'Age_at_Marriage', 'Gender', 'Education_Level', 'Caste_Match', 'Religion', 'Parental_Approval', 'Urban_Rural', 'Dowry_Exchanged', 'Marital_Satisfaction', 'Divorce_Status', 'Children_Count', 'Income_Level', 'Years_Since_Marriage', 'Spouse_Working', 'Inter-Caste', 'Inter-Religion']\n",
      "\n",
      "First few rows:\n",
      "   ID Marriage_Type  Age_at_Marriage  Gender Education_Level Caste_Match  \\\n",
      "0   1          Love               23    Male        Graduate   Different   \n",
      "1   2          Love               28  Female          School        Same   \n",
      "2   3      Arranged               39    Male    Postgraduate        Same   \n",
      "3   4      Arranged               26  Female          School   Different   \n",
      "4   5          Love               32  Female        Graduate        Same   \n",
      "\n",
      "  Religion Parental_Approval Urban_Rural Dowry_Exchanged Marital_Satisfaction  \\\n",
      "0    Hindu                No       Urban              No               Medium   \n",
      "1    Hindu               Yes       Rural             Yes                  Low   \n",
      "2   Muslim               Yes       Rural              No               Medium   \n",
      "3    Hindu               Yes       Urban             Yes                  Low   \n",
      "4    Hindu           Partial       Rural             Yes               Medium   \n",
      "\n",
      "  Divorce_Status  Children_Count Income_Level  Years_Since_Marriage  \\\n",
      "0            Yes               5       Middle                    34   \n",
      "1             No               3       Middle                    42   \n",
      "2             No               0         High                    25   \n",
      "3             No               0         High                    12   \n",
      "4             No               1       Middle                    41   \n",
      "\n",
      "  Spouse_Working Inter-Caste Inter-Religion  \n",
      "0             No          No             No  \n",
      "1             No          No            Yes  \n",
      "2             No          No             No  \n",
      "3             No         Yes             No  \n",
      "4             No          No            Yes  \n",
      "\n",
      "Unique values in Marriage_Type: ['Love' 'Arranged']\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS OF CONTINUOUS VARIABLES BY MARRIAGE TYPE\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Analyzing Age_at_Marriage by Marriage_Type\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Descriptive Statistics for Age_at_Marriage by Marriage_Type:\n",
      "               count       mean       std  min  median  max\n",
      "Marriage_Type                                              \n",
      "Arranged        6022  28.473929  6.291108   18    29.0   39\n",
      "Love            3978  28.549020  6.262567   18    29.0   39\n",
      "\n",
      "Test for Normality (Shapiro-Wilk):\n",
      "Group 'Love': p = 0.0000 - Not normal\n",
      "Group 'Arranged': p = 0.0000 - Not normal\n",
      "\n",
      "Independent Samples t-test:\n",
      "t = 0.5858, p = 0.5580\n",
      "Result: No significant difference\n",
      "Effect size (Cohen's d): 0.0120\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Mann-Whitney U test:\n",
      "U = 12059695.0000, p = 0.5616\n",
      "Result: No significant difference\n",
      "Effect size (r): 0.0058\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Creating visualizations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 6022.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot saved as 'Age_at_Marriage_by_Marriage_Type_boxplot.png'.\n",
      "Density plot saved as 'Age_at_Marriage_by_Marriage_Type_density.png'.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Analyzing Years_Since_Marriage by Marriage_Type\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Descriptive Statistics for Years_Since_Marriage by Marriage_Type:\n",
      "               count       mean        std  min  median  max\n",
      "Marriage_Type                                               \n",
      "Arranged        6022  25.224676  14.091917    1    25.0   49\n",
      "Love            3978  24.594017  13.991730    1    25.0   49\n",
      "\n",
      "Test for Normality (Shapiro-Wilk):\n",
      "Group 'Love': p = 0.0000 - Not normal\n",
      "Group 'Arranged': p = 0.0000 - Not normal\n",
      "\n",
      "Independent Samples t-test:\n",
      "t = -2.1998, p = 0.0278\n",
      "Result: Significant difference\n",
      "Effect size (Cohen's d): 0.0449\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Mann-Whitney U test:\n",
      "U = 11666819.0000, p = 0.0277\n",
      "Result: Significant difference\n",
      "Effect size (r): 0.0220\n",
      "This represents a negligible effect size.\n",
      "\n",
      "Creating visualizations...\n",
      "Boxplot saved as 'Years_Since_Marriage_by_Marriage_Type_boxplot.png'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 6022.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density plot saved as 'Years_Since_Marriage_by_Marriage_Type_density.png'.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "SUMMARY OF STATISTICAL TESTS\n",
      "======================================================================\n",
      "            Variable      Test Used Test Statistic p-value Significant  Normality\n",
      "     Age_at_Marriage Mann-Whitney U  12059695.0000  0.5616          No Non-normal\n",
      "Years_Since_Marriage Mann-Whitney U  11666819.0000  0.0277         Yes Non-normal\n",
      "\n",
      "INTERPRETATION OF RESULTS:\n",
      "\n",
      "- No significant difference in Age_at_Marriage between marriage types (p=0.5616).\n",
      "  * Mann-Whitney U was used since the data is not normally distributed.\n",
      "\n",
      "- Years_Since_Marriage is significantly different between marriage types (p=0.0277).\n",
      "  * Arranged marriages have higher Years_Since_Marriage values on average.\n",
      "  * The mean difference is 0.63 units.\n",
      "  * Mann-Whitney U was used since the data is not normally distributed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, shapiro, levene\n",
    "import os\n",
    "\n",
    "# Set file path for the data\n",
    "file_path = r\"C:\\Users\\Aru\\Downloads\\archive\\marriage_data_india.csv\"\n",
    "\n",
    "# Function to check if column exists in dataset\n",
    "def check_column(df, column_name):\n",
    "    if column_name not in df.columns:\n",
    "        # Try to find a case-insensitive match\n",
    "        matches = [col for col in df.columns if col.lower() == column_name.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "        else:\n",
    "            return None\n",
    "    return column_name\n",
    "\n",
    "# Function to perform statistical tests for continuous variables\n",
    "def analyze_continuous_by_group(df, cont_var, group_var):\n",
    "    \"\"\"\n",
    "    Analyze a continuous variable by a categorical grouping variable\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The data\n",
    "    cont_var (str): Continuous variable name\n",
    "    group_var (str): Grouping variable name\n",
    "    \n",
    "    Returns:\n",
    "    dict: Results of the analysis\n",
    "    \"\"\"\n",
    "    # Get correct column names\n",
    "    cont_var_col = check_column(df, cont_var)\n",
    "    group_var_col = check_column(df, group_var)\n",
    "    \n",
    "    # Skip if any column doesn't exist\n",
    "    if not cont_var_col or not group_var_col:\n",
    "        print(f\"\\nSkipping analysis: Could not find columns {cont_var} or {group_var}\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy with only non-missing values for this analysis\n",
    "    test_df = df[[cont_var_col, group_var_col]].dropna()\n",
    "    \n",
    "    # Skip if too few data points after dropping missing values\n",
    "    if len(test_df) < 10:\n",
    "        print(f\"\\nSkipping analysis: Too few non-missing values for {cont_var_col} vs {group_var_col}\")\n",
    "        return None\n",
    "    \n",
    "    # Check if continuous variable is actually numeric\n",
    "    if not pd.api.types.is_numeric_dtype(test_df[cont_var_col]):\n",
    "        try:\n",
    "            test_df[cont_var_col] = pd.to_numeric(test_df[cont_var_col], errors='coerce')\n",
    "            test_df = test_df.dropna()\n",
    "            print(f\"\\nConverted {cont_var_col} to numeric type.\")\n",
    "        except:\n",
    "            print(f\"\\nCould not convert {cont_var_col} to numeric. Skipping analysis.\")\n",
    "            return None\n",
    "    \n",
    "    # Check if grouping variable has at least 2 groups\n",
    "    if test_df[group_var_col].nunique() < 2:\n",
    "        print(f\"\\nSkipping analysis: {group_var_col} has fewer than 2 groups.\")\n",
    "        return None\n",
    "    \n",
    "    # Get unique values of the grouping variable\n",
    "    groups = test_df[group_var_col].unique()\n",
    "    \n",
    "    # Basic descriptive statistics by group\n",
    "    group_stats = test_df.groupby(group_var_col)[cont_var_col].agg(['count', 'mean', 'std', 'min', 'median', 'max'])\n",
    "    print(f\"\\nDescriptive Statistics for {cont_var_col} by {group_var_col}:\")\n",
    "    print(group_stats)\n",
    "    \n",
    "    # Test for normality for each group\n",
    "    normality_results = {}\n",
    "    for group in groups:\n",
    "        group_data = test_df[test_df[group_var_col] == group][cont_var_col]\n",
    "        if len(group_data) >= 3:  # Shapiro-Wilk requires at least 3 observations\n",
    "            stat, p = shapiro(group_data)\n",
    "            normality_results[group] = {\n",
    "                'statistic': stat,\n",
    "                'p_value': p,\n",
    "                'normal': p > 0.05\n",
    "            }\n",
    "    \n",
    "    print(\"\\nTest for Normality (Shapiro-Wilk):\")\n",
    "    for group, result in normality_results.items():\n",
    "        print(f\"Group '{group}': p = {result['p_value']:.4f} - {'Normal' if result['normal'] else 'Not normal'}\")\n",
    "    \n",
    "    # Decide if all groups are normally distributed\n",
    "    all_normal = all(result['normal'] for result in normality_results.values()) if normality_results else False\n",
    "    \n",
    "    # If dealing with 2 groups, check equality of variances (for t-test)\n",
    "    if len(groups) == 2 and all_normal:\n",
    "        group1_data = test_df[test_df[group_var_col] == groups[0]][cont_var_col]\n",
    "        group2_data = test_df[test_df[group_var_col] == groups[1]][cont_var_col]\n",
    "        \n",
    "        # Levene's test for homogeneity of variance\n",
    "        try:\n",
    "            levene_stat, levene_p = levene(group1_data, group2_data)\n",
    "            equal_var = levene_p > 0.05\n",
    "            print(f\"\\nTest for Equal Variances (Levene's test):\")\n",
    "            print(f\"p = {levene_p:.4f} - {'Equal variances' if equal_var else 'Unequal variances'}\")\n",
    "        except:\n",
    "            print(\"\\nCould not perform Levene's test. Assuming unequal variances.\")\n",
    "            equal_var = False\n",
    "    else:\n",
    "        equal_var = False\n",
    "    \n",
    "    # Decide which test to use based on normality and number of groups\n",
    "    if len(groups) == 2:  # Two groups\n",
    "        group1 = groups[0]\n",
    "        group2 = groups[1]\n",
    "        group1_data = test_df[test_df[group_var_col] == group1][cont_var_col]\n",
    "        group2_data = test_df[test_df[group_var_col] == group2][cont_var_col]\n",
    "        \n",
    "        # Perform both parametric and non-parametric tests\n",
    "        # 1. Independent t-test (parametric)\n",
    "        try:\n",
    "            t_stat, t_p = ttest_ind(group1_data, group2_data, equal_var=equal_var)\n",
    "            print(f\"\\nIndependent Samples t-test:\")\n",
    "            print(f\"t = {t_stat:.4f}, p = {t_p:.4f}\")\n",
    "            print(f\"Result: {'Significant difference' if t_p < 0.05 else 'No significant difference'}\")\n",
    "            \n",
    "            # Calculate Cohen's d effect size for t-test\n",
    "            if len(group1_data) > 0 and len(group2_data) > 0:\n",
    "                mean1, mean2 = group1_data.mean(), group2_data.mean()\n",
    "                sd1, sd2 = group1_data.std(), group2_data.std()\n",
    "                n1, n2 = len(group1_data), len(group2_data)\n",
    "                \n",
    "                # Pooled standard deviation\n",
    "                pooled_sd = np.sqrt(((n1 - 1) * sd1**2 + (n2 - 1) * sd2**2) / (n1 + n2 - 2))\n",
    "                \n",
    "                # Cohen's d\n",
    "                if pooled_sd > 0:\n",
    "                    cohens_d = abs(mean1 - mean2) / pooled_sd\n",
    "                    print(f\"Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "                    \n",
    "                    # Interpret Cohen's d\n",
    "                    if cohens_d < 0.2:\n",
    "                        effect = \"negligible\"\n",
    "                    elif cohens_d < 0.5:\n",
    "                        effect = \"small\"\n",
    "                    elif cohens_d < 0.8:\n",
    "                        effect = \"medium\"\n",
    "                    else:\n",
    "                        effect = \"large\"\n",
    "                    print(f\"This represents a {effect} effect size.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not perform t-test: {e}\")\n",
    "            t_stat, t_p = None, None\n",
    "        \n",
    "        # 2. Mann-Whitney U test (non-parametric)\n",
    "        try:\n",
    "            u_stat, u_p = mannwhitneyu(group1_data, group2_data)\n",
    "            print(f\"\\nMann-Whitney U test:\")\n",
    "            print(f\"U = {u_stat:.4f}, p = {u_p:.4f}\")\n",
    "            print(f\"Result: {'Significant difference' if u_p < 0.05 else 'No significant difference'}\")\n",
    "            \n",
    "            # Calculate effect size for Mann-Whitney U (r = Z / sqrt(N))\n",
    "            n = len(group1_data) + len(group2_data)\n",
    "            if n > 0:\n",
    "                # Calculate Z from U\n",
    "                mean_u = (len(group1_data) * len(group2_data)) / 2\n",
    "                sd_u = np.sqrt((len(group1_data) * len(group2_data) * (n + 1)) / 12)\n",
    "                if sd_u > 0:\n",
    "                    z = (u_stat - mean_u) / sd_u\n",
    "                    r = abs(z) / np.sqrt(n)\n",
    "                    print(f\"Effect size (r): {r:.4f}\")\n",
    "                    \n",
    "                    # Interpret r\n",
    "                    if r < 0.1:\n",
    "                        effect = \"negligible\"\n",
    "                    elif r < 0.3:\n",
    "                        effect = \"small\"\n",
    "                    elif r < 0.5:\n",
    "                        effect = \"medium\"\n",
    "                    else:\n",
    "                        effect = \"large\"\n",
    "                    print(f\"This represents a {effect} effect size.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not perform Mann-Whitney U test: {e}\")\n",
    "            u_stat, u_p = None, None\n",
    "        \n",
    "        # Decide which test to use for final results\n",
    "        if all_normal:\n",
    "            # Use t-test for normal data\n",
    "            final_test = \"t-test\"\n",
    "            final_stat = t_stat\n",
    "            final_p = t_p\n",
    "        else:\n",
    "            # Use Mann-Whitney for non-normal data\n",
    "            final_test = \"Mann-Whitney U\"\n",
    "            final_stat = u_stat\n",
    "            final_p = u_p\n",
    "        \n",
    "        # Return results\n",
    "        return {\n",
    "            'variable': cont_var_col,\n",
    "            'group_variable': group_var_col,\n",
    "            'descriptive_stats': group_stats,\n",
    "            'normality': all_normal,\n",
    "            'equal_variances': equal_var if 'equal_var' in locals() else None,\n",
    "            'recommended_test': final_test,\n",
    "            'final_statistic': final_stat,\n",
    "            'final_p_value': final_p,\n",
    "            'significant': final_p < 0.05 if final_p is not None else None,\n",
    "            'groups': groups\n",
    "        }\n",
    "    else:\n",
    "        # For more than 2 groups, we would use ANOVA or Kruskal-Wallis\n",
    "        # Not implemented here as the question focuses on Marriage_Type which has 2 values\n",
    "        print(\"\\nAnalysis for more than 2 groups not implemented in this script.\")\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    # Check if file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from {file_path}\")\n",
    "        print(f\"Number of records: {len(df)}\")\n",
    "        print(\"\\nColumns in the dataset:\")\n",
    "        print(df.columns.tolist())\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"File not found at: {file_path}\")\n",
    "        print(\"Creating sample data for demonstration instead.\")\n",
    "        \n",
    "        # Create sample data for demonstration\n",
    "        np.random.seed(42)\n",
    "        n = 500\n",
    "        \n",
    "        # Create sample data with meaningful patterns\n",
    "        marriage_type = np.random.choice(['Love', 'Arranged'], size=n, p=[0.4, 0.6])\n",
    "        \n",
    "        # Age_at_Marriage - slightly lower for love marriages on average\n",
    "        age_at_marriage = np.where(marriage_type == 'Love',\n",
    "                      np.random.normal(24, 4, n),  # Love marriages: mean age 24\n",
    "                      np.random.normal(27, 4, n))  # Arranged marriages: mean age 27\n",
    "        \n",
    "        # Years_Since_Marriage - slightly shorter for love marriages on average\n",
    "        years_since_marriage = np.where(marriage_type == 'Love',\n",
    "                                       np.random.gamma(4, 1, n),  # Love marriages: shorter duration\n",
    "                                       np.random.gamma(6, 1, n))  # Arranged marriages: longer duration\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Marriage_Type': marriage_type,\n",
    "            'Age_at_Marriage': age_at_marriage,\n",
    "            'Years_Since_Marriage': years_since_marriage\n",
    "        })\n",
    "        \n",
    "        print(\"\\nNote: This is sample data. Please verify the file path and try again.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading the data: {e}\")\n",
    "    # Create sample data as a fallback\n",
    "    np.random.seed(42)\n",
    "    n = 500\n",
    "    \n",
    "    # Create basic sample data\n",
    "    marriage_type = np.random.choice(['Love', 'Arranged'], size=n, p=[0.4, 0.6])\n",
    "    age_at_marriage = np.random.normal(25, 5, n)\n",
    "    years_since_marriage = np.random.gamma(5, 1, n)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Marriage_Type': marriage_type,\n",
    "        'Age_at_Marriage': age_at_marriage,\n",
    "        'Years_Since_Marriage': years_since_marriage\n",
    "    })\n",
    "\n",
    "# Get the correct column name for Marriage_Type\n",
    "marriage_type_col = check_column(df, 'Marriage_Type')\n",
    "if not marriage_type_col:\n",
    "    print(\"Error: Marriage_Type column not found in the dataset.\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    exit()\n",
    "\n",
    "# Print unique values of Marriage_Type to verify\n",
    "print(f\"\\nUnique values in {marriage_type_col}: {df[marriage_type_col].unique()}\")\n",
    "\n",
    "# Continuous variables to test against Marriage_Type\n",
    "continuous_vars = ['Age_at_Marriage', 'Years_Since_Marriage']\n",
    "\n",
    "# Analyze each continuous variable\n",
    "results = []\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS OF CONTINUOUS VARIABLES BY MARRIAGE TYPE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for var in continuous_vars:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(f\"Analyzing {var} by {marriage_type_col}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    result = analyze_continuous_by_group(df, var, marriage_type_col)\n",
    "    \n",
    "    if result:\n",
    "        # Add to results list\n",
    "        results.append(result)\n",
    "        \n",
    "        # Create visualizations\n",
    "        print(\"\\nCreating visualizations...\")\n",
    "        \n",
    "        # 1. Box plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.boxplot(x=marriage_type_col, y=var, data=df)\n",
    "        ax.set_title(f\"{var} by {marriage_type_col}\")\n",
    "        \n",
    "        # Add statistical annotation\n",
    "        if result['final_p_value'] is not None:\n",
    "            sig_text = f\"p = {result['final_p_value']:.4f}\"\n",
    "            if result['significant']:\n",
    "                sig_text += \" *\"\n",
    "            plt.text(0.5, 0.01, sig_text, \n",
    "                     horizontalalignment='center',\n",
    "                     verticalalignment='bottom',\n",
    "                     transform=ax.transAxes,\n",
    "                     fontsize=12)\n",
    "        \n",
    "        try:\n",
    "            plt.savefig(f\"{var}_by_{marriage_type_col}_boxplot.png\")\n",
    "            print(f\"Boxplot saved as '{var}_by_{marriage_type_col}_boxplot.png'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not save boxplot: {e}\")\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Density plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for group in result['groups']:\n",
    "            group_data = df[df[marriage_type_col] == group][var].dropna()\n",
    "            sns.kdeplot(group_data, label=group)\n",
    "        \n",
    "        plt.title(f\"Distribution of {var} by {marriage_type_col}\")\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        \n",
    "        try:\n",
    "            plt.savefig(f\"{var}_by_{marriage_type_col}_density.png\")\n",
    "            print(f\"Density plot saved as '{var}_by_{marriage_type_col}_density.png'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not save density plot: {e}\")\n",
    "            \n",
    "        plt.close()\n",
    "\n",
    "# Create a summary table\n",
    "if results:\n",
    "    summary_data = []\n",
    "    for result in results:\n",
    "        if result['final_p_value'] is not None:\n",
    "            summary_data.append({\n",
    "                'Variable': result['variable'],\n",
    "                'Test Used': result['recommended_test'],\n",
    "                'Test Statistic': f\"{result['final_statistic']:.4f}\" if result['final_statistic'] is not None else 'N/A',\n",
    "                'p-value': f\"{result['final_p_value']:.4f}\" if result['final_p_value'] is not None else 'N/A',\n",
    "                'Significant': 'Yes' if result['significant'] else 'No',\n",
    "                'Normality': 'Normal' if result['normality'] else 'Non-normal'\n",
    "            })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nSUMMARY OF STATISTICAL TESTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Print final interpretation\n",
    "    print(\"\\nINTERPRETATION OF RESULTS:\")\n",
    "    for result in results:\n",
    "        var = result['variable']\n",
    "        if result['significant']:\n",
    "            # Get group means\n",
    "            stats = result['descriptive_stats']\n",
    "            mean_diff = abs(stats.loc[result['groups'][0], 'mean'] - stats.loc[result['groups'][1], 'mean'])\n",
    "            \n",
    "            # Determine which group has higher mean\n",
    "            higher_group = result['groups'][0] if stats.loc[result['groups'][0], 'mean'] > stats.loc[result['groups'][1], 'mean'] else result['groups'][1]\n",
    "            \n",
    "            print(f\"\\n- {var} is significantly different between marriage types (p={result['final_p_value']:.4f}).\")\n",
    "            print(f\"  * {higher_group} marriages have higher {var} values on average.\")\n",
    "            print(f\"  * The mean difference is {mean_diff:.2f} units.\")\n",
    "            print(f\"  * {result['recommended_test']} was used since the data is {'normally' if result['normality'] else 'not normally'} distributed.\")\n",
    "        else:\n",
    "            print(f\"\\n- No significant difference in {var} between marriage types (p={result['final_p_value']:.4f}).\")\n",
    "            print(f\"  * {result['recommended_test']} was used since the data is {'normally' if result['normality'] else 'not normally'} distributed.\")\n",
    "else:\n",
    "    print(\"\\nNo valid results to summarize. Please check your data and file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, arrianged marriages have higher Years_Since_Marriage at statistically significant level, according to Mann Whitney tests which were used to substitute due to non-normal distribution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results do not necessarily mean that arranged marriages are key to longevity in marriage. In fact, cultural pressures may still inhibit divorce from unhealthy relationships in India. \n",
    "As India develops, improvements in job climates, healthcare infrastructure, and attitudes, may need for this analysis to be replicated, as these can affect divorce rates. \n",
    "This analysis also suggests that arranged marriages are common across all demographics. \n",
    "However, 60% of this sample contained arranged marriages, which may have skewed results. \n",
    "It is reccomended that future samples be close to a 50/50 split between arranged and love marriages, keeping in mind that whilst the majority of Indians are arranged marriages, it may be only temporary. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
